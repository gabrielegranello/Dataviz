{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data viz projecy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and clean it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and convert the date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"UK-HPI-full-file-2023-02.csv\"); # load the data\n",
    "df_reduced=df[['Date', 'RegionName', 'AreaCode', 'AveragePrice']].copy(); # extract the data that refer only to restrict number of columns.\n",
    "df_reduced['Date'] = pd.to_datetime(df['Date'],dayfirst=True); # By default, the date is imported as object. However, it is better to convert the date column from object to date class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the data matching a specific adate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analysis= np.datetime64('2023-01-01'); # in the first phase, will only work with the data for a give date\n",
    "df_grouped=df_reduced[df_reduced.Date==time_analysis].copy(); # extract the dataset for that given date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard any macro-region (e.g. England) from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 401 entries, 228 to 135313\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          401 non-null    datetime64[ns]\n",
      " 1   RegionName    401 non-null    object        \n",
      " 2   AreaCode      401 non-null    object        \n",
      " 3   AveragePrice  401 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "regions_to_discard=['England','Scotland','Wales','Northern Ireland']; # We will work with local authorities, so we can discard high level geographical boundaries. Create a list with the elements to discard.\n",
    "df_final=df_grouped[~df_grouped.RegionName.isin(regions_to_discard)].copy(); # find the rows where the region name is equal a value within the list. The function returns true when the values are met. The ~ operator swaps true and false.\n",
    "df_final.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the data in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Date'] = df_final['Date'].dt.strftime('%Y-%m-%d')\n",
    "df_final.to_json(path_or_buf='HPI.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
