{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data viz projecy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and clean it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and convert the date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"UK-HPI-full-file-2023-02.csv\"); # load the data\n",
    "df_reduced=df[['Date', 'RegionName', 'AreaCode', 'AveragePrice']].copy(); # extract the data that refer only to restrict number of columns.\n",
    "df_reduced['Date'] = pd.to_datetime(df['Date'],dayfirst=True); # By default, the date is imported as object. However, it is better to convert the date column from object to date class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the data matching a specific adate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analysis= np.datetime64('2023-01-01'); # in the first phase, will only work with the data for a give date\n",
    "df_grouped=df_reduced[df_reduced.Date==time_analysis].copy(); # extract the dataset for that given date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard any macro-region (e.g. England) from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 401 entries, 228 to 135313\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          401 non-null    datetime64[ns]\n",
      " 1   RegionName    401 non-null    object        \n",
      " 2   AreaCode      401 non-null    object        \n",
      " 3   AveragePrice  401 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "regions_to_discard=['England','Scotland','Wales','Northern Ireland']; # We will work with local authorities, so we can discard high level geographical boundaries. Create a list with the elements to discard.\n",
    "df_final=df_grouped[~df_grouped.RegionName.isin(regions_to_discard)].copy(); # find the rows where the region name is equal a value within the list. The function returns true when the values are met. The ~ operator swaps true and false.\n",
    "df_final.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the data in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Date'] = df_final['Date'].dt.strftime('%Y-%m-%d')\n",
    "df_final.to_json(path_or_buf='HPI.json', orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the json file with the coordinates of the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_england = json.load(open('England.json'));  # read the data for England\n",
    "json_scotalnd= json.load(open('Scotland.json')); # read the data for Scotland\n",
    "json_wales=json.load(open('Wales.json')); # read the data for Wales\n",
    "json_northerireland=json.load(open('NortherIrland.json')); # read the data for Norther Ireland\n",
    "df_england=pd.json_normalize(json_england['features']); # convert json into dataframe\n",
    "df_scotland=pd.json_normalize(json_scotalnd['features']); # convert json into dataframe\n",
    "df_wales=pd.json_normalize(json_wales['features']); # convert json into dataframe\n",
    "df_northerireland=pd.json_normalize(json_northerireland['features']); # convert json into dataframe\n",
    "df_greatbritain=pd.concat([df_england,df_scotland,a,df_northerireland]); # combine all the dataframes together"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norther Ireland use a different column for storing the region name and region number. Combine them under the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greatbritain['properties.LAD13NM']=df_greatbritain['properties.LAD13NM'].fillna(df_greatbritain['properties.LGDNAME']);\n",
    "df_greatbritain['properties.LAD13CD']=df_greatbritain['properties.LAD13CD'].fillna(df_greatbritain['properties.LGDCode']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greatbritain=df_greatbritain[['properties.LAD13CD','properties.LAD13NM','geometry.type','geometry.coordinates']]; # retain only some columns\n",
    "df_greatbritain=df_greatbritain.rename(columns={ \"properties.LAD13CD\": \"AreaCode\", \"properties.LAD13NM\": \"RegionName\",\n",
    "                                     \"geometry.type\":\"geometry_type\",\"geometry.coordinates\":\"geometry_coordinates\"}); # rename the columns to easier names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 695 entries, 0 to 10\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   AreaCode              695 non-null    object \n",
      " 1   RegionName            695 non-null    object \n",
      " 2   geometry_type         695 non-null    object \n",
      " 3   geometry_coordinates  695 non-null    object \n",
      " 4   Averageprice          0 non-null      float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_greatbritain['Averageprice']=np.nan\n",
    "df_greatbritain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code,price in zip(df_final.AreaCode,df_final.AveragePrice):\n",
    "    df_greatbritain.loc[df_greatbritain.AreaCode==code,'Averageprice']=price;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 695 entries, 0 to 10\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   AreaCode              695 non-null    object \n",
      " 1   RegionName            695 non-null    object \n",
      " 2   geometry_type         695 non-null    object \n",
      " 3   geometry_coordinates  695 non-null    object \n",
      " 4   Averageprice          607 non-null    float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_greatbritain.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
